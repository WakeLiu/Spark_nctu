{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked',\n",
       " '1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/5 21171,7.25,,S',\n",
       " '2,1,1,\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",female,38,1,0,PC 17599,71.2833,C85,C']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local[*]\")\n",
    "train_rdd = sc.textFile(\"./input/train.csv\")\n",
    "test_rdd = sc.textFile(\"./input/test.csv\")\n",
    "train_rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse RDD to DF\n",
    "def parseTrain(rdd):\n",
    "    # step 1\n",
    "    header = rdd.first()\n",
    "    body = rdd.filter(lambda r: r!=header)\n",
    "    \n",
    "    # prepare for step 2\n",
    "    def parseRow(row):\n",
    "        row_list = row.replace('\"','').split(',')\n",
    "        row_tuple = tuple(row_list)\n",
    "        return row_tuple\n",
    "    \n",
    "    # step2\n",
    "    rdd_parsed = body.map(parseRow)\n",
    " \n",
    "    # step 3\n",
    "    colnames = header.split(',')\n",
    "    colnames.insert(3,'FirstName')\n",
    " \n",
    "    return rdd_parsed.toDF(colnames)\n",
    "\n",
    "def parseTest(rdd):\n",
    "    # step 1\n",
    "    header = rdd.first()\n",
    "    body = rdd.filter(lambda r: r!=header)\n",
    " \n",
    "    def parseRow(row):\n",
    "        row_list = row.replace('\"','').split(',')\n",
    "        row_tuple = tuple(row_list)\n",
    "        return row_tuple\n",
    "    \n",
    "    # step2\n",
    "    rdd_parsed = body.map(parseRow)\n",
    "    \n",
    "    # step 3\n",
    "    colnames = header.split(',')\n",
    "    colnames.insert(2,'FirstName')\n",
    "    \n",
    "    return rdd_parsed.toDF(colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+---------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|FirstName|                Name|   Sex|Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+---------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|   Braund|     Mr. Owen Harris|  male| 22|    1|    0|       A/5 21171|   7.25|     |       S|\n",
      "|          2|       1|     1|  Cumings| Mrs. John Bradle...|female| 38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen|         Miss. Laina|female| 26|    0|    0|STON/O2. 3101282|  7.925|     |       S|\n",
      "|          4|       1|     1| Futrelle| Mrs. Jacques Hea...|female| 35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|    Allen|   Mr. William Henry|  male| 35|    0|    0|          373450|   8.05|     |       S|\n",
      "+-----------+--------+------+---------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "train_df = parseTrain(train_rdd)\n",
    "test_df = parseTest(test_rdd)\n",
    "\n",
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+---------+--------------------+------+----+-----+-----+-------+-------+-----+--------+\n",
      "|PassengerId|Pclass|FirstName|                Name|   Sex| Age|SibSp|Parch| Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+------+---------+--------------------+------+----+-----+-----+-------+-------+-----+--------+\n",
      "|        892|     3|    Kelly|           Mr. James|  male|34.5|    0|    0| 330911| 7.8292|     |       Q|\n",
      "|        893|     3|   Wilkes| Mrs. James (Elle...|female|  47|    1|    0| 363272|      7|     |       S|\n",
      "|        894|     2|    Myles|  Mr. Thomas Francis|  male|  62|    0|    0| 240276| 9.6875|     |       Q|\n",
      "|        895|     3|     Wirz|          Mr. Albert|  male|  27|    0|    0| 315154| 8.6625|     |       S|\n",
      "|        896|     3| Hirvonen| Mrs. Alexander (...|female|  22|    1|    1|3101298|12.2875|     |       S|\n",
      "+-----------+------+---------+--------------------+------+----+-----+-----+-------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+---------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+-----+\n",
      "|PassengerId|Survived|Pclass|FirstName|                Name|   Sex|Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked| Mark|\n",
      "+-----------+--------+------+---------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+-----+\n",
      "|          1|       0|     3|   Braund|     Mr. Owen Harris|  male| 22|    1|    0|       A/5 21171|   7.25|     |       S|train|\n",
      "|          2|       1|     1|  Cumings| Mrs. John Bradle...|female| 38|    1|    0|        PC 17599|71.2833|  C85|       C|train|\n",
      "|          3|       1|     3|Heikkinen|         Miss. Laina|female| 26|    0|    0|STON/O2. 3101282|  7.925|     |       S|train|\n",
      "|          4|       1|     1| Futrelle| Mrs. Jacques Hea...|female| 35|    1|    0|          113803|   53.1| C123|       S|train|\n",
      "|          5|       0|     3|    Allen|   Mr. William Henry|  male| 35|    0|    0|          373450|   8.05|     |       S|train|\n",
      "+-----------+--------+------+---------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Add Survived column to test\n",
    "from pyspark.sql.functions import lit, col\n",
    "train_df = train_df.withColumn('Mark',lit('train')) #新增一欄Mark,分成train 跟test 兩種型態\n",
    "test_df = (test_df.withColumn('Survived',lit(0)).withColumn('Mark',lit('test')))\n",
    "\n",
    "test_df = test_df[train_df.columns]#這句話的意思？\n",
    "## Append Test data to Train data\n",
    "df = train_df.unionAll(test_df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Mark: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: double (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: double (nullable = true)\n",
      " |-- Parch: double (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Mark: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#transform it into “feature vectors”.將其中五個型態轉為double\n",
    "df = (df.withColumn('Age',df['Age'].cast(\"double\"))\\\n",
    "      .withColumn('SibSp',df['SibSp'].cast(\"double\")) \\\n",
    "      .withColumn('Parch',df['Parch'].cast(\"double\")) \\\n",
    "      .withColumn('Fare',df['Fare'].cast(\"double\")) \\\n",
    "      .withColumn('Survived',df['Survived'].cast(\"double\")) \\\n",
    ")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Survived': 0, 'Age': 0, 'SibSp': 0, 'Parch': 0, 'Fare': 0, 'Sex': 0, 'Embarked': 0}\n"
     ]
    }
   ],
   "source": [
    "#針對這五個variable,檢查有哪些數字是missing的\n",
    "numVars = ['Survived','Age','SibSp','Parch','Fare','Sex']\n",
    "def countNull(df,var):\n",
    "    return df.where(df[var].isNull()).count()\n",
    " \n",
    "missing = {var: countNull(df,var) for var in numVars}\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#missing 的數字填上平均值\n",
    "age_mean = df.groupBy().mean('Age').first()[0]\n",
    "fare_mean = df.groupBy().mean('Fare').first()[0]\n",
    "df = df.na.fill({'Age':age_mean,'Fare':fare_mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                Name|Title|\n",
      "+--------------------+-----+\n",
      "|     Mr. Owen Harris|   Mr|\n",
      "| Mrs. John Bradle...|  Mrs|\n",
      "|         Miss. Laina| Miss|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#取得名字跟title\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    " \n",
    "## created user defined function to extract title\n",
    "getTitle = udf(lambda name: name.split('.')[0].strip(),StringType())\n",
    "df = df.withColumn('Title', getTitle(df['Name']))\n",
    " \n",
    "df.select('Name','Title').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: double (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: double (nullable = false)\n",
      " |-- SibSp: double (nullable = true)\n",
      " |-- Parch: double (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = false)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Mark: string (nullable = false)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Sex: double (nullable = true)\n",
      "\n",
      "+---+\n",
      "|sex|\n",
      "+---+\n",
      "|0.0|\n",
      "|1.0|\n",
      "|1.0|\n",
      "|1.0|\n",
      "|0.0|\n",
      "+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "catVars = ['Pclass','Sex','Embarked','Title']\n",
    "\n",
    "## index Sex variable\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "si = StringIndexer(inputCol = 'Sex', outputCol = 'Sex_indexed')\n",
    "df_indexed = si.fit(df).transform(df).drop('Sex').withColumnRenamed('Sex_indexed','Sex')\n",
    "\n",
    "df_indexed.printSchema()\n",
    "df_indexed.select('sex').show(5)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+\n",
      "|Embarked|Embarked_indexed|\n",
      "+--------+----------------+\n",
      "|       S|             0.0|\n",
      "|       C|             1.0|\n",
      "|       S|             0.0|\n",
      "|       S|             0.0|\n",
      "+--------+----------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## make use of pipeline to index all categorical variables\n",
    "def indexer(df,col):\n",
    "    si = StringIndexer(inputCol = col, outputCol = col+'_indexed').fit(df)\n",
    "    return si\n",
    " \n",
    "indexers = [indexer(df,col) for col in catVars]\n",
    " \n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = indexers)\n",
    "df_indexed = pipeline.fit(df).transform(df)\n",
    " \n",
    "df_indexed.select('Embarked','Embarked_indexed').show(4)#Embark有空字串會怎麼處理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
